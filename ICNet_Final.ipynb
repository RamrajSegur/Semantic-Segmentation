{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Add, UpSampling2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import model_from_yaml\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras import backend as K\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify horizontally flipped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(path):\n",
    "    head, tail=os.path.split(path)\n",
    "    if tail.startswith('h'):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img=mpimg.imread(path)\n",
    "    gate=check(path)\n",
    "    if gate==True:\n",
    "        img=img[120:600,0:800] # Appropriate crop for horizontal flipped image\n",
    "    else:\n",
    "        img=img[96:480,0:800]\n",
    "    h, w, d = img.shape\n",
    "    img=cv2.resize(img, dsize=((w//32)*32,(h//32)*32),interpolation=cv2.INTER_NEAREST) # Resizing the images in the factor of 32. Floor division of the original size and multiplying with 32\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "   \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load label as numpy array compatible for training (three upcoming cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/4 size Label image preparation\n",
    "def load_label(path):\n",
    "    img=mpimg.imread(path)\n",
    "    gate=check(path)\n",
    "    if gate==True:\n",
    "        img=img[120:600,0:800]\n",
    "    else:\n",
    "        img=img[96:480,0:800]\n",
    "    h, w, d=img.shape\n",
    "    img_new=cv2.resize(img, dsize=((w//32)*8,(h//32)*8),interpolation=cv2.INTER_NEAREST)\n",
    "    img_decoded=img_new[:,:,0]*255\n",
    "    img_decoded=img_decoded.astype(int)\n",
    "    img_coded=np.zeros_like(img_new[:,:,0])\n",
    "    for i in range((img_new.shape[0])):\n",
    "        for j in range((img_new.shape[1])):\n",
    "            if img_decoded[i][j]==10.0:            \n",
    "                img_coded[i][j]=2\n",
    "\n",
    "            elif img_decoded[i][j]==7.0:\n",
    "                img_coded[i][j]=1\n",
    "                \n",
    "            else:\n",
    "                img_coded[i][j]=0\n",
    "            \n",
    "    img_coded=np.array(img_coded,dtype=np.uint8)\n",
    "    y=np.zeros((1,img_new.shape[0],img_new.shape[1],3),dtype=np.float32)\n",
    "    for i in range(img_new.shape[0]):\n",
    "        for j in range(img_new.shape[1]):\n",
    "            y[0,i,j,img_coded[i][j]]=1\n",
    "            \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/8 size Label image preparation\n",
    "def load_label1(path):\n",
    "    img=mpimg.imread(path)\n",
    "    gate=check(path)\n",
    "    if gate==True:\n",
    "        img=img[120:600,0:800]\n",
    "    else:\n",
    "        img=img[96:480,0:800]\n",
    "    h, w, d=img.shape\n",
    "    img_new=cv2.resize(img, dsize=((w//32)*4,(h//32)*4),interpolation=cv2.INTER_NEAREST)\n",
    "    img_decoded=img_new[:,:,0]*255\n",
    "    img_decoded=img_decoded.astype(int)\n",
    "    img_coded=np.zeros_like(img_new[:,:,0])\n",
    "    for i in range((img_new.shape[0])):\n",
    "        for j in range((img_new.shape[1])):\n",
    "            if img_decoded[i][j]==10.0:            \n",
    "                img_coded[i][j]=2\n",
    "\n",
    "            elif img_decoded[i][j]==7.0:\n",
    "                img_coded[i][j]=1\n",
    "                \n",
    "            else:\n",
    "                img_coded[i][j]=0\n",
    "            \n",
    "    img_coded=np.array(img_coded,dtype=np.uint8)\n",
    "    y=np.zeros((1,img_new.shape[0],img_new.shape[1],3),dtype=np.float32)\n",
    "    for i in range(img_new.shape[0]):\n",
    "        for j in range(img_new.shape[1]):\n",
    "            y[0,i,j,img_coded[i][j]]=1                \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/16 size Label image preparation\n",
    "def load_label2(path):\n",
    "    img=mpimg.imread(path)\n",
    "    gate=check(path)\n",
    "    if gate==True:\n",
    "        img=img[120:600,0:800]\n",
    "    else:\n",
    "        img=img[96:480,0:800]\n",
    "    h, w, d=img.shape\n",
    "    img_new=cv2.resize(img, dsize=((w//32)*2,(h//32)*2),interpolation=cv2.INTER_NEAREST)\n",
    "    img_decoded=img_new[:,:,0]*255\n",
    "    img_decoded=img_decoded.astype(int)\n",
    "    img_coded=np.zeros_like(img_new[:,:,0])\n",
    "    for i in range((img_new.shape[0])):\n",
    "        for j in range((img_new.shape[1])):\n",
    "            if img_decoded[i][j]==10.0:            \n",
    "                img_coded[i][j]=2\n",
    "\n",
    "            elif img_decoded[i][j]==7.0:\n",
    "                img_coded[i][j]=1\n",
    "                \n",
    "            else:\n",
    "                img_coded[i][j]=0\n",
    "            \n",
    "    img_coded=np.array(img_coded,dtype=np.uint8)\n",
    "    y=np.zeros((1,img_new.shape[0],img_new.shape[1],3),dtype=np.float32)\n",
    "    for i in range(img_new.shape[0]):\n",
    "        for j in range(img_new.shape[1]):\n",
    "            y[0,i,j,img_coded[i][j]]=1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate arrays from images and labels in the path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_arrays_from_file(path, image_dir, label_dir):\n",
    "    while 1:\n",
    "        f = open(path)\n",
    "        for line in f:\n",
    "            filename = line.rstrip('\\n')\n",
    "            path_image = os.path.join(image_dir, filename)\n",
    "            path_label = os.path.join(label_dir, filename)\n",
    "            x = load_image(path_image)\n",
    "            w = load_label(path_label)\n",
    "            y = load_label1(path_label)\n",
    "            z = load_label2(path_label)\n",
    "            yield (x, [w, y, z])\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize tensors for the network (three upcoming cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the size to half\n",
    "def Resizer1(img):\n",
    "    from keras.backend import tf as ktf\n",
    "    return_image=ktf.image.resize_bilinear(img, size=(int(img.shape[1])//2, int(img.shape[2])//2))   \n",
    "    return return_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce the size based on argument\n",
    "def Resizer2(img,value):\n",
    "    from keras.backend import tf as ktf\n",
    "    return_image=ktf.image.resize_bilinear(img,size=value)    \n",
    "    return return_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increase the size (doubling)\n",
    "def Resizer3(img):\n",
    "    from keras.backend import tf as ktf\n",
    "    return_image=ktf.image.resize_bilinear(img,size=(int(img.shape[1])*2,int(img.shape[2])*2))    \n",
    "    return return_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network (ICNet - Image Cascade Network) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(width,height,train=False):  \n",
    "    import tensorflow as tf\n",
    "    inp = Input(shape=(height,width, 3))\n",
    "    x = Lambda(lambda x: x)(inp)\n",
    "\n",
    "    # (1/2)\n",
    "    y = Lambda(Resizer1, name='Resize1')(x)\n",
    "    y = Conv2D(32, 3, strides=2, padding='same', activation='relu', name='Conv1/2_1')(y)\n",
    "    y = BatchNormalization(name='BN_1')(y)\n",
    "    y = Conv2D(32, 3, padding='same', activation='relu', name='conv1/2_2')(y)\n",
    "    y = BatchNormalization(name='BN_2')(y)\n",
    "    y = Conv2D(64, 3, padding='same', activation='relu', name='conv1/2_3')(y)\n",
    "    y = BatchNormalization(name='BN_3')(y)\n",
    "    y_ = MaxPooling2D(pool_size=3, strides=2, name='Pool_1/2_1')(y)\n",
    "    \n",
    "    y = Conv2D(64, 1, activation='relu', name='Conv1/2_4')(y_)\n",
    "    y = BatchNormalization(name='BN_4')(y)\n",
    "    y = ZeroPadding2D(name='Padding1')(y)\n",
    "    y = Conv2D(32, 3, activation='relu', name='conv1/2_5')(y)\n",
    "    y = BatchNormalization(name='BN_5')(y)\n",
    "    y = Conv2D(64, 1, name='conv1/2_6')(y)\n",
    "    y = BatchNormalization(name='BN_6')(y)\n",
    "    y = Add(name='Add1')([y,y_])\n",
    "    y_ = Activation('relu', name='RELU_1')(y)\n",
    "\n",
    "    y = Conv2D(256, 1, strides=2, name='Conv1/2_7')(y_)\n",
    "    y = BatchNormalization(name='BN_7')(y)\n",
    "    y_ = Conv2D(64, 1, strides=2, activation='relu', name='Conv1/2_8')(y_)\n",
    "    y_ = BatchNormalization(name='BN_8')(y_) \n",
    "    y_ = ZeroPadding2D(name='Padding2')(y_)\n",
    "    y_ = Conv2D(64, 3, activation='relu', name='Conv1/2_9')(y_)\n",
    "    y_ = BatchNormalization(name='BN_9')(y_)\n",
    "    y_ = Conv2D(256, 1, name='Conv1/2_10')(y_)\n",
    "    y_ = BatchNormalization(name='BN_10')(y_)\n",
    "    y = Add(name='Add2')([y,y_])\n",
    "    z = Activation('relu', name='RELU_2')(y)\n",
    "\n",
    "    # (1/4)\n",
    "    y_ = Lambda(Resizer1, name='Resizer2')(z)\n",
    "    y = Conv2D(64, 1, activation='relu', name='Conv1/4_1')(y_)\n",
    "    y = BatchNormalization(name='BN_11')(y)\n",
    "    y = ZeroPadding2D(name='Padding3')(y)\n",
    "    y = Conv2D(64, 3, activation='relu', name='Conv1/4_2')(y)\n",
    "    y = BatchNormalization(name='BN_12')(y)\n",
    "    y = Conv2D(256, 1, name='Conv1/4_3')(y)\n",
    "    y = BatchNormalization(name='BN_13')(y)\n",
    "    y = Add(name='Add3')([y,y_])\n",
    "    y_ = Activation('relu', name='RELU_3')(y)\n",
    "\n",
    "    y = Conv2D(256, 1, activation='relu', name='Conv1/4_4')(y_)\n",
    "    y = BatchNormalization(name='BN_14')(y)\n",
    "    y = ZeroPadding2D(name='Padding4')(y)\n",
    "    y = Conv2D(64, 3, activation='relu', name='Conv1/4_5')(y)\n",
    "    y = BatchNormalization(name='BN_15')(y)\n",
    "    y = Conv2D(256, 1, name='Conv1/4_6')(y)\n",
    "    y = BatchNormalization(name='BN_16')(y)\n",
    "    y = Add(name='Add4')([y,y_])\n",
    "    y_ = Activation('relu', name='RELU_4')(y)\n",
    "\n",
    "    y = Conv2D(512, 1, name='Conv1/4_7')(y_)\n",
    "    y = BatchNormalization(name='BN_17')(y)\n",
    "    y_ = Conv2D(128, 1, activation='relu', name='Conv1/4_8')(y_)\n",
    "    y_ = BatchNormalization(name='BN_18')(y_)\n",
    "    y_ = ZeroPadding2D(padding=2, name='Padding5')(y_)\n",
    "    y_ = Conv2D(128, 3, dilation_rate=2, activation='relu', name='Conv1/4_9')(y_)\n",
    "    y_ = BatchNormalization(name='BN_19')(y_)\n",
    "    y_ = Conv2D(512, 1, name='Conv1/4_10')(y_)\n",
    "    y_ = BatchNormalization(name='BN_20')(y_)\n",
    "    y = Add(name='Add5')([y,y_])\n",
    "    y_ = Activation('relu', name='RELU_5')(y)\n",
    "\n",
    "    y = Conv2D(128, 1, activation='relu', name='Conv1/4_11')(y_)\n",
    "    y = BatchNormalization(name='BN_21')(y)\n",
    "    y = ZeroPadding2D(padding=2, name='Padding6')(y)\n",
    "    y = Conv2D(128, 3, dilation_rate=2, activation='relu', name='Conv1/4_12')(y)\n",
    "    y = BatchNormalization(name='BN_22')(y)\n",
    "    y = Conv2D(512, 1, name='Conv1/4_13')(y)\n",
    "    y = BatchNormalization(name='BN_23')(y)\n",
    "    y = Add(name='Add6')([y,y_])\n",
    "    y_ = Activation('relu', name='RELU_6')(y)\n",
    "\n",
    "    y = Conv2D(128, 1, activation='relu', name='Conv1/4_14')(y_)\n",
    "    y = BatchNormalization(name='BN_24')(y)\n",
    "    y = ZeroPadding2D(padding=2, name='Padding7')(y)\n",
    "    y = Conv2D(128, 3, dilation_rate=2, activation='relu', name='Conv1/4_15')(y)\n",
    "    y = BatchNormalization(name='BN_25')(y)\n",
    "    y = Conv2D(512, 1, name='Conv1/4_16')(y)\n",
    "    y = BatchNormalization(name='BN_26')(y)\n",
    "    y = Add(name='Add7')([y,y_])\n",
    "    y_ = Activation('relu', name='RELU_7')(y)\n",
    "\n",
    "    y = Conv2D(128, 1, activation='relu', name='Conv1/4_17')(y_)\n",
    "    y = BatchNormalization(name='BN_27')(y)\n",
    "    y = ZeroPadding2D(padding=2, name='Padding8')(y)\n",
    "    y = Conv2D(128, 3, dilation_rate=2, activation='relu', name='Conv1/4_18')(y)\n",
    "    y = BatchNormalization(name='BN_28')(y)\n",
    "    y = Conv2D(512, 1, name='Conv1/4_19')(y)\n",
    "    y = BatchNormalization(name='BN_29')(y)\n",
    "    y = Add(name='Add8')([y,y_])\n",
    "    y = Activation('relu', name='RELU_8')(y)\n",
    "\n",
    "    y_ = Conv2D(1024, 1, name='Conv1/4_20')(y)\n",
    "    y_ = BatchNormalization(name='BN_30')(y_)\n",
    "    y = Conv2D(256, 1, activation='relu', name='Conv1/4_21')(y)\n",
    "    y = BatchNormalization(name='BN_31')(y)\n",
    "    y = ZeroPadding2D(padding=4, name='Padding9')(y)\n",
    "    y = Conv2D(256, 3, dilation_rate=4, activation='relu', name='Conv1/4_22')(y)\n",
    "    y = BatchNormalization(name='BN_32')(y)\n",
    "    y = Conv2D(1024, 1, name='Conv1/4_23')(y)\n",
    "    y = BatchNormalization(name='BN_33')(y)\n",
    "    y = Add(name='Add9')([y,y_])\n",
    "    y_ = Activation('relu', name='RELU_9')(y)\n",
    "\n",
    "    y = Conv2D(256, 1, activation='relu', name='Conv1/4_24')(y_)\n",
    "    y = BatchNormalization(name='BN_34')(y)\n",
    "    y = ZeroPadding2D(padding=4, name='Padding10')(y)\n",
    "    y = Conv2D(256, 3, dilation_rate=4, activation='relu', name='Conv1/4_25')(y)\n",
    "    y = BatchNormalization(name='BN_35')(y)\n",
    "    y = Conv2D(1024, 1, name='Conv1/4_26')(y)\n",
    "    y = BatchNormalization(name='BN_36')(y)\n",
    "    y = Add(name='Add10')([y,y_])\n",
    "    y_ = Activation('relu', name='RELU_10')(y)\n",
    "\n",
    "    y = Conv2D(256, 1, activation='relu', name='Conv1/4_27')(y_)\n",
    "    y = BatchNormalization(name='BN_37')(y)\n",
    "    y = ZeroPadding2D(padding=4, name='Padding11')(y)\n",
    "    y = Conv2D(256, 3, dilation_rate=4, activation='relu', name='Conv1/4_28')(y)\n",
    "    y = BatchNormalization(name='BN_38')(y)\n",
    "    y = Conv2D(1024, 1, name='Conv1/4_29')(y)\n",
    "    y = BatchNormalization(name='BN_39')(y)\n",
    "    y = Add(name='Add11')([y,y_])\n",
    "    y = Activation('relu', name='RELU_11')(y)\n",
    "\n",
    "    h, w = y.shape[1:3].as_list()\n",
    "    pool1 = AveragePooling2D(pool_size=(h,w), strides=(h,w), name='Avg_Pool_1')(y)\n",
    "    pool1 = Lambda(Resizer2, arguments={'value':[h,w]}, name='Resizer3')(pool1)\n",
    "    pool2 = AveragePooling2D(pool_size=(h/2,w/2), strides=(h//2,w//2), name='Avg_Pool_2')(y)\n",
    "    pool2 = Lambda(Resizer2, arguments={'value':[h,w]}, name='Resizer4')(pool2)\n",
    "    pool3 = AveragePooling2D(pool_size=(h/3,w/3), strides=(h//3,w//3), name='Avg_Pool_3')(y)\n",
    "    pool3 = Lambda(Resizer2, arguments={'value':[h,w]}, name='Resizer5')(pool3)\n",
    "    pool6 = AveragePooling2D(pool_size=(h/4,w/4), strides=(h//4,w//4), name='Avg_Pool_4')(y)\n",
    "    pool6 = Lambda(Resizer2, arguments={'value':[h,w]}, name='Resizer6')(pool6)\n",
    "\n",
    "    y = Add(name='Add12')([y, pool1, pool2, pool3, pool6])\n",
    "    y = Conv2D(256, 1, activation='relu', name='Conv1/4_30')(y)\n",
    "    y = BatchNormalization(name='BN_40')(y)\n",
    "    aux_1 = Lambda(Resizer3, name='Resizer7')(y)\n",
    "    y = ZeroPadding2D(padding=2, name='Padding12')(aux_1)\n",
    "    y = Conv2D(128, 3, dilation_rate=2, name='Conv1/4_31')(y)\n",
    "    y = BatchNormalization(name='BN_41')(y)\n",
    "    y_ = Conv2D(128, 1, name='Conv1/4_32')(z)\n",
    "    y_ = BatchNormalization(name='BN_42')(y_)\n",
    "    y = Add(name='Add13')([y,y_])\n",
    "    y = Activation('relu', name='RELU_12')(y)\n",
    "\n",
    "    aux_2 = Lambda(Resizer3, name='Resizer8')(y)\n",
    "    y = ZeroPadding2D(padding=2, name='Padding13')(aux_2)\n",
    "    y_ = Conv2D(128, 3, dilation_rate=2, name='Conv1/4_33')(y)\n",
    "    y_ = BatchNormalization(name='BN_43')(y_)\n",
    "\n",
    "    # (1)\n",
    "    y = Conv2D(32, 3, strides=2, padding='same', activation='relu', name='Conv1_1')(x)\n",
    "    y = BatchNormalization(name='BN_44')(y)\n",
    "    y = Conv2D(32, 3, strides=2, padding='same', activation='relu', name='Conv1_2')(y)\n",
    "    y = BatchNormalization(name='BN_45')(y)\n",
    "    y = Conv2D(64, 3, strides=2, padding='same', activation='relu', name='Conv1_3')(y)\n",
    "    y = BatchNormalization(name='BN_46')(y)\n",
    "    y = Conv2D(128, 1, name='Conv1_4')(y)\n",
    "    y = BatchNormalization(name='BN_47')(y)\n",
    "\n",
    "    y = Add(name='sub12_sum')([y,y_])\n",
    "    y = Activation('relu', name='RELU_13')(y)\n",
    "    y = Lambda(Resizer3, name='Resizer9')(y)\n",
    "    \n",
    "    n_classes=3\n",
    "    \n",
    "    out = Conv2D(n_classes, 1, activation='softmax', name='Out3')(y)\n",
    "    \n",
    "    if train:\n",
    "        aux_1 = Conv2D(n_classes, 1, activation='softmax', name='Out1')(aux_1)\n",
    "        aux_2 = Conv2D(n_classes, 1, activation='softmax', name='Out2')(aux_2)\n",
    "        model = Model(inputs=inp, outputs=[out, aux_2, aux_1])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom cost function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def weighted_binary_crossentropy():\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        weights=tf.count_nonzero(y_true,axis=1,keep_dims=True)\n",
    "        weights=tf.to_float(weights)\n",
    "        loss = (y_true * K.log(y_pred)+(1-y_true)*K.log(1-y_pred))*(1-(weights/tf.to_float(tf.size(y_true)/3)))\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=network(800,384,train=True)\n",
    "model.compile(loss=weighted_binary_crossentropy(),loss_weights=[10,4.0,4.0],optimizer='adam',metrics=['accuracy'])\n",
    "nb_data=200\n",
    "tbCallBack=TensorBoard(log_dir='./Keras_Log3', histogram_freq=0, write_graph=True, write_images=True)\n",
    "class_weight={0:1,1:2,2:2.5}\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    model.fit_generator(\n",
    "            generate_arrays_from_file('Train/Train/Files31.txt','Train/Train/CameraRGB','Train/Train/CameraSeg' ),\n",
    "            steps_per_epoch=nb_data,shuffle=True, validation_data=generate_arrays_from_file('Train/Train/Files31.txt','Train/Train/CameraRGB','Train/Train/CameraSeg' ), validation_steps=10,\n",
    "            epochs=100,callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model architecture and weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yaml = model.to_yaml()\n",
    "with open(\"model_architecture.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "model.save_weights(\"model_weights.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
